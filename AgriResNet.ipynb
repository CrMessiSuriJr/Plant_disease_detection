{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrMessiSuriJr/Plant_disease_detection/blob/main/AgriResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40npGOZe5mf3",
        "outputId": "030fc054-2ac4-4cda-fb7e-c755cbd82a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: jupyter_http_over_ws in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.4)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.4.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.22.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter) (7.7.1)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_http_over_ws) (1.16.0)\n",
            "Requirement already satisfied: tornado>=4.5 in /usr/local/lib/python3.10/dist-packages (from jupyter_http_over_ws) (6.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (3.1.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.9.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.1.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.16.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.2.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.0.1)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.1.30)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum) (12.3.101)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter) (3.0.43)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Collecting Pillow\n",
            "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: jupyter_http_over_ws in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.4)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.1.30)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter) (7.7.1)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_http_over_ws) (1.16.0)\n",
            "Requirement already satisfied: tornado>=4.5 in /usr/local/lib/python3.10/dist-packages (from jupyter_http_over_ws) (6.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (5.9.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.1.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.16.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.2.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter) (3.0.43)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n"
          ]
        }
      ],
      "source": [
        "# @markdown Installing required files/libraries and updating previously intsalled\n",
        "!pip install captum lime jupyter jupyter_http_over_ws kaggle tensorboardX\n",
        "!pip install --upgrade torch torchvision Pillow matplotlib scikit-image scikit-learn captum lime jupyter jupyter_http_over_ws kaggle tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWpPZad0t_O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f920fd3-e3bc-450a-9ead-d61f0caa8430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enabling: jupyter_http_over_ws\n",
            "- Writing config: /root/.jupyter\n",
            "    - Validating...\n",
            "      jupyter_http_over_ws 0.0.7 \u001b[32mOK\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @markdown Importing libraries: torch, os, random, shutil, google.colab, PIL, matplotlib, Install&Import captum etc...\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except:\n",
        "    pass\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import captum.attr as captum_attr\n",
        "from captum.attr import GuidedGradCam\n",
        "\n",
        "import numpy as np\n",
        "from lime import lime_image\n",
        "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from lime.lime_image import LimeImageExplainer\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from PIL import UnidentifiedImageError\n",
        "import time\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!jupyter serverextension enable --py jupyter_http_over_ws\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTYDOim3t_--"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing and augmentation\n",
        "dim = 224 # @param {type:\"integer\"}\n",
        "crop_dim = 224 # @param {type:\"integer\"}\n",
        "norm_mean = [0.0]*3\n",
        "norm_std = [0.0]*3\n",
        "norm_mean[0] = 0.485 # @param\n",
        "norm_mean[1] = 0.456 # @param\n",
        "norm_mean[2] = 0.406 # @param\n",
        "norm_std[0] = 0.229 # @param\n",
        "norm_std[1] = 0.224 # @param\n",
        "norm_std[2] = 0.225 # @param\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((dim, dim)),  # Resize images to a fixed size\n",
        "    transforms.CenterCrop(crop_dim),     # Center crop to 224x224 pixels\n",
        "    transforms.ToTensor(),          # Convert to PyTorch tensor\n",
        "    transforms.Normalize(mean=norm_mean, std=norm_std)  # Normalize\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGWwriDt_4H1"
      },
      "outputs": [],
      "source": [
        "# @markdown Define the dataset path\n",
        "local = False # @param {type:\"boolean\"}\n",
        "if not local: dataset_path = '/content/' # @param {type:\"string\"}\n",
        "else: dataset_path = \".\\\\08112023\\\\\"\n",
        "\n",
        "# @markdown Define the ratio for the train-test split\n",
        "split_ratio = 0.7  # 70% for training, 30% for testing\n",
        "\n",
        "# @markdown Specify the path to your dataset on Google Drive\n",
        "drive_dataset_path = \"PlantVillage\" # @param {type:\"string\"}\n",
        "drive_dataset_path = dataset_path + drive_dataset_path + (\"\\\\\" if local else \"/\")\n",
        "\n",
        "\n",
        "# @markdown Create train and test directories if they don't exist\n",
        "base_dir = dataset_path # @param {type:\"string\"}\n",
        "\n",
        "train_dir = base_dir + \"train\" # @markdown train_dir = base_dir + \"\\train\"\n",
        "\n",
        "test_dir = base_dir + \"test\" # @markdown test_dir = base_dir + \"\\test\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# @markdown Function to check if an image can be opened without errors\n",
        "def is_valid_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iurZZrsB_s2y"
      },
      "outputs": [],
      "source": [
        "to_download_data = True # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj5Z2qJhxDrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "547bdb63-c394-4e6d-a23c-a9020fb0e2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'content-length'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/PlantVillage/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-a90324ecc1a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mclass_folders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_folders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"desktop.ini\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclass_folders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/PlantVillage/'"
          ]
        }
      ],
      "source": [
        "if to_download_data:\n",
        "    # @markdown #Please set the path to your Kaggle API key from Google Drive\n",
        "    kaggle_api_key_path = \"/content/kaggle/kaggle.json\" # @param {type:\"string\"}\n",
        "    # @markdown ^^^The folder containing kaggle.json api file, in Google-drive for file persistence\n",
        "\n",
        "    # @markdown Copy the Kaggle API key to the required directory\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp \"$kaggle_api_key_path\" ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    # @markdown Importing kaggle for api access for dataset download\n",
        "    try:\n",
        "        import kaggle\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # @markdown Replace 'your_dataset_folder' with the Kaggle dataset name\n",
        "    dataset_name = 'emmarex/plantdisease' # @param {type:\"string\"}\n",
        "\n",
        "    # @markdown Download the dataset using Kaggle API\n",
        "    try:\n",
        "        if (to_download_data): kaggle.api.dataset_download_files(dataset_name, unzip=True, path = dataset_path)  # Download and unzip the dataset to the './data' directory\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    class_folders = os.listdir(drive_dataset_path)\n",
        "    for i in class_folders:\n",
        "        if \"desktop.ini\" in i: class_folders.remove(i)\n",
        "\n",
        "    # @markdown Iterate through each class folder\n",
        "    for class_folder in class_folders:\n",
        "        class_path = os.path.join(drive_dataset_path, class_folder)\n",
        "\n",
        "        # @markdown List all the image files in the current class folder\n",
        "        all_files = os.listdir(class_path)\n",
        "\n",
        "        # @markdown Randomly shuffle the list of files\n",
        "        random.shuffle(all_files)\n",
        "\n",
        "        # @markdown Calculate the number of files for training and testing within the current class\n",
        "        num_total_files = len(all_files)\n",
        "        num_train_files = int(split_ratio * num_total_files)\n",
        "        num_test_files = num_total_files - num_train_files\n",
        "\n",
        "        # @markdown Create train and test subdirectories within the class folder\n",
        "        class_train_dir = os.path.join(train_dir, class_folder)\n",
        "        class_test_dir = os.path.join(test_dir, class_folder)\n",
        "        os.makedirs(class_train_dir, exist_ok=True)\n",
        "        os.makedirs(class_test_dir, exist_ok=True)\n",
        "\n",
        "        # @markdown Move the first num_train_files files to the train subdirectory and the rest to the test subdirectory\n",
        "        for i, file_name in enumerate(all_files):\n",
        "            source_path = os.path.join(class_path, file_name)\n",
        "            file_name = f\"img_{i}.jpg\"\n",
        "            if i < num_train_files and is_valid_image(source_path):\n",
        "                destination_path = os.path.join(class_train_dir, file_name)\n",
        "            else:\n",
        "                if is_valid_image(source_path):\n",
        "                    destination_path = os.path.join(class_test_dir, file_name)\n",
        "            shutil.copy(source_path, destination_path)\n",
        "else:\n",
        "    # @markdown List all the class folders in your dataset directory\n",
        "    class_folders = os.listdir(drive_dataset_path)\n",
        "    for i in class_folders:\n",
        "        if \"desktop.ini\" in i: class_folders.remove(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zdEItwbPoWu"
      },
      "outputs": [],
      "source": [
        "# @markdown Iterate through your dataset and check each image\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(drive_dataset_path, class_folder)\n",
        "    for image_file in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "        if not is_valid_image(image_path):\n",
        "            print(f\"Invalid image: {image_path}\")\n",
        "            print(f\"\\n\\n\\nDeleting file { {image_path}}...\\n\\n\\n\")\n",
        "            !rm \"$image_path\"\n",
        "\n",
        "# @markdown Create ImageFolder datasets for training and testing (excluding problematic images)\n",
        "try:\n",
        "    torch.cuda.empty_cache()\n",
        "finally:\n",
        "    pass\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# @markdown Define batch size and number of workers for data loading (adjust as needed)\n",
        "batch_size = 128 # @param {type:\"integer\"}\n",
        "num_workers = 2 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Create a DataLoader for the training dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "# @markdown You can iterate through this train_loader in your training loop\\\n",
        "# @markdown &emsp;&emsp;Continue with your training loop and data loading using test_loader\n",
        "for inputs,labels in test_loader: continue\n",
        "# @markdown &emsp;&emsp;Continue with your training loop and data loading using train_loader\n",
        "for inputs,labels in train_loader: continue\n",
        "print(inputs.shape,labels.shape)\n",
        "\n",
        "# @markdown Print the class names (based on folder names)\n",
        "class_names = train_dataset.classes\n",
        "print(\"Class names:\", class_names)\n",
        "print(\"Num of classes:\",len(class_names))\n",
        "\n",
        "# @markdown Print the number of samples in the training and testing sets\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of testing samples:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcqFR8VZD_pb"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\".join([str(i)+\":\"+str(j) for i,j in enumerate(class_folders)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v41DJDkdONxv"
      },
      "outputs": [],
      "source": [
        "# @markdown (DEPRECATED) error causing file removal\n",
        "img_num = 221  # @param {type:\"integer\"}\n",
        "train_folder = True # @param {type:\"boolean\"}\n",
        "folder_index = 1 # @param {type:\"slider\", min:0, max:14, step:1}\n",
        "file_name = base_dir + (\"train/\" if train_folder else \"test/\") + class_folders[folder_index] +\"/img_\"+str(img_num)+\".jpg\"\n",
        "to_delete = True # @param {type:\"boolean\"}\n",
        "if (to_delete):\n",
        "    !rm \"$file_name\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnx-_bjDHPlK"
      },
      "outputs": [],
      "source": [
        "# Define the  Custom ResNet model\n",
        "class CustomResNetlayer(nn.Module):\n",
        "    def __init__(self, num_classes, inner_dim = 32):\n",
        "        super(CustomResNetlayer, self).__init__()\n",
        "\n",
        "        Activation = nn.Sigmoid\n",
        "\n",
        "        self.feature_head_l1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2048, 2048, kernel_size=3),\n",
        "            nn.BatchNorm2d(2048, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            nn.Conv2d(2048, inner_dim, kernel_size=3),\n",
        "            nn.BatchNorm2d(inner_dim, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            Activation(),\n",
        "        )\n",
        "        self.feature_head_l2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(inner_dim, inner_dim, kernel_size=3),\n",
        "            nn.BatchNorm2d(inner_dim, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            nn.Conv2d( inner_dim, inner_dim, kernel_size=3),\n",
        "            nn.BatchNorm2d(inner_dim, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            Activation(),\n",
        "        )\n",
        "        self.feature_head_l3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(inner_dim, 2048, kernel_size=3),\n",
        "            nn.BatchNorm2d(2048, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            nn.Conv2d( 2048, 2048, kernel_size=3),\n",
        "            nn.BatchNorm2d(2048, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "\n",
        "            Activation(),\n",
        "        )\n",
        "\n",
        "        self.residual_fc_l12 = nn.Sequential(\n",
        "            nn.Conv2d( inner_dim+2048, inner_dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(inner_dim, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "            Activation(),\n",
        "        )\n",
        "        self.residual_fc_l2 = nn.Sequential(\n",
        "            nn.Conv2d( inner_dim*2, inner_dim, kernel_size=1),\n",
        "            nn.BatchNorm2d(inner_dim, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "            Activation(),\n",
        "        )\n",
        "        self.residual_fc_l23 = nn.Sequential(\n",
        "            nn.Conv2d( inner_dim+2048, 2048, kernel_size=1),\n",
        "            nn.BatchNorm2d(2048, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
        "            Activation(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        input = x\n",
        "\n",
        "        y = self.feature_head_l1(x)\n",
        "        y = torch.cat((x,y),dim=1)\n",
        "        x = self.residual_fc_l12(y)\n",
        "\n",
        "        y = self.feature_head_l2(x)\n",
        "        y = torch.cat((x,y),dim=1)\n",
        "        x = self.residual_fc_l2(y)\n",
        "\n",
        "        y = self.feature_head_l3(x)\n",
        "        y = torch.cat((x,y),dim=1)\n",
        "        x = self.residual_fc_l23(y)\n",
        "\n",
        "        return x + input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEwVNCum88EG"
      },
      "outputs": [],
      "source": [
        "# @markdown empty cuda cache through torch\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    finally:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiFYCEH31O4e"
      },
      "outputs": [],
      "source": [
        "num_classes = len(train_dataset.classes)\n",
        "inner_dim = 16 # @param {type:\"integer\"}\n",
        "\n",
        "# Setup an instance of your CustomResNet model\n",
        "\n",
        "# Load the ResNet architecture\n",
        "try: del model, optimizer, scheduler\n",
        "except: pass\n",
        "finally: model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace the last layer of the ResNet model\n",
        "model.avgpool = nn.Sequential(\n",
        "                CustomResNetlayer(num_classes,inner_dim),\n",
        "                model.avgpool,\n",
        "                )\n",
        "model.fc = nn.Sequential(\n",
        "            model.fc,\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear( model.fc.out_features, num_classes),\n",
        "        )\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.avgpool.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Move the model to the specified device (GPU or CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define your loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU38r_SREyv1"
      },
      "outputs": [],
      "source": [
        "try: del scheduler, optimizer\n",
        "except: pass\n",
        "lr = 0.003 # @param {type:\"number\"}\n",
        "weight_decay = 0.001 # @param {type:\"number\"}\n",
        "optimizer = optim.AdamW(model.parameters(), lr = lr, betas = (0.9, 0.999), eps = 1e-08, weight_decay = weight_decay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v05q6lj_8V_"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter()\n",
        "writer.add_graph(model, input_to_model = inputs.to(device))\n",
        "\n",
        "%load_ext tensorboard\n",
        "# export scalar data to JSON for external processing\n",
        "writer.export_scalars_to_json(\"./runs/all_scalars.json\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPeIU_dd_-Qm"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjLlVlQvuH3J"
      },
      "outputs": [],
      "source": [
        "# @markdown Training loop\n",
        "num_epochs = 20 # @param {type:\"integer\"}\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min = 5e-6)\n",
        "\n",
        "model.train()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.avgpool.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    t1 = time.time()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {(running_loss / len(train_loader)):.5f}, Time taken: {(time.time()-t1):.3f}s')\n",
        "print(f\"Total time taken: {(time.time()-t0):.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G78I66uuMce"
      },
      "outputs": [],
      "source": [
        "# @markdown Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5pm_QH3ue43"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# @markdown Get true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "# @markdown Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=range(num_classes))\n",
        "\n",
        "# @markdown Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes).plot(cmap='viridis', values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WQvS0eeukwt"
      },
      "outputs": [],
      "source": [
        "# @markdown Load the test dataset\n",
        "reload_test_data = False # @param {type:\"boolean\"}\n",
        "if (reload_test_data):\n",
        "    test_dataset = datasets.ImageFolder(test_dir, transform=transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "# @markdown Define a function to compute GradCAM\n",
        "def compute_gradcam(input_image, target_class):\n",
        "    model.eval()\n",
        "    input_image = input_image.to(device)\n",
        "    target_class = torch.tensor(target_class).to(device)\n",
        "\n",
        "    # @markdown Create a GradCAM object\n",
        "    gradcam = captum_attr.GuidedGradCam(model, model.avgpool[0].residual_fc_l23[0])\n",
        "\n",
        "    # @markdown Compute attribution scores\n",
        "    attribution = gradcam.attribute(input_image, target=target_class)\n",
        "\n",
        "    # @markdown Detach the attribution tensor from the computation graph\n",
        "    attribution = attribution.detach()\n",
        "\n",
        "    return attribution\n",
        "\n",
        "# @markdown Choose an image and target class index for GradCAM visualization\n",
        "image_no_for_input = 420 # @param {type:\"integer\"}\n",
        "image, label = test_dataset[image_no_for_input]\n",
        "\n",
        "# @markdown Transpose the image to [channels, height, width]\n",
        "#image = image.permute(1, 2, 0)\n",
        "\n",
        "# @markdown Compute GradCAM\n",
        "attribution = compute_gradcam(image.unsqueeze(0), label)\n",
        "attribution = (attribution - attribution.min())/(attribution.max() - attribution.min())\n",
        "\n",
        "def norm_(img):\n",
        "    out = (img - img.min())/(img.max() - img.min())\n",
        "    return out\n",
        "\n",
        "# @markdown Visualize the GradCAM heatmap\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(norm_(attribution).squeeze(0).permute(1, 2, 0).cpu(), cmap='viridis')\n",
        "plt.title('GradCAM Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McDAPo3curBQ"
      },
      "outputs": [],
      "source": [
        "# @markdown Define a function to create a Lime explainer and explain predictions\n",
        "\"\"\"\n",
        "# @markdown &emsp;Now we are ready to define classification function that Lime needs.\\\n",
        "# @markdown &emsp;The input to this function is numpy array of images where each image is ndarray \\\n",
        "# @markdown &emsp;of shape (channel, height, width). The output is numpy aaray of shape \\\n",
        "# @markdown &emsp;(image index, classes) where each value in array should be probability for that \\\n",
        "# @markdown &emsp;image, class combination.\n",
        "\"\"\"\n",
        "preprocess_transform = transforms.Compose([\n",
        "    transforms.Resize((dim, dim)),  # Resize images to a fixed size\n",
        "    transforms.CenterCrop(crop_dim),     # Center crop to crop_dim * crop_dim pixels\n",
        "    transforms.Normalize(mean=norm_mean, std=norm_std)  # Normalize\n",
        "])\n",
        "def batch_predict(images):\n",
        "    model.eval()\n",
        "    if len(images.shape) > 3: batch = torch.stack([preprocess_transform(torch.from_numpy(i).permute(2, 0, 1)) for i in images], dim=0)\n",
        "    else: batch = preprocess_transform(torch.from_numpy(i)).permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    logits = model(batch)\n",
        "    probs = nn.Softmax(dim=1)(logits)\n",
        "    return probs.detach().cpu().numpy()\n",
        "\n",
        "def explain_lime(image, model, num_classes):\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "    explanation = explainer.explain_instance(image, model, top_labels = num_classes, num_samples=4096)\n",
        "    return explanation\n",
        "\n",
        "# @markdown Choose an image to explain\n",
        "image_no_for_input = 420 # @param {type:\"integer\"}\n",
        "image, label = test_dataset[image_no_for_input]\n",
        "explanation = explain_lime(image.permute(1, 2, 0).numpy(), batch_predict, num_classes)\n",
        "\n",
        "# @markdown Visualize the Lime explanation\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "                                            label,\n",
        "                                            positive_only=False,\n",
        "                                            num_features=5,\n",
        "                                            hide_rest=False\n",
        "                                            )\n",
        "\n",
        "plt.imshow(mark_boundaries(norm_(temp) / 2 + 0.5, mask), cmap='viridis')\n",
        "plt.title('LIME Explanation')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7Jka7FukC3"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.imshow(norm_(test_dataset[420][0]).permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyDaYaT0utyO"
      },
      "outputs": [],
      "source": [
        "# @markdown Get feature representations for a subset of your data\n",
        "num_samples = 8192  # @param {type:\"integer\"}\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, batch_labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        features.extend(outputs.cpu().numpy())\n",
        "        labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "features = features[:num_samples]\n",
        "labels = labels[:num_samples]\n",
        "\n",
        "# @markdown Perform t-SNE\n",
        "feat = np.stack(features)\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(feat)\n",
        "\n",
        "# @markdown Visualize t-SNE plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='viridis', alpha=0.7)\n",
        "plt.colorbar()\n",
        "plt.title('t-SNE Plot')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yMjsEUveprVB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}